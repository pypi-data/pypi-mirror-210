(undo-tree-save-format-version . 1)
"7fa10524767b986ef613aee8606df1ae5138f4ec"
[nil nil nil nil (25657 44625 819230 306000) 0 nil]
([nil nil ((713 . 717) (#("DEBUG" 0 5 (fontified t)) . 713) (undo-tree-id0 . -5) (undo-tree-id1 . -5) (undo-tree-id2 . -4) (t 25650 615 19803 375000)) nil (25657 44625 819224 383000) 0 nil])
([nil nil ((4299 . 4376) (t 25657 44625 836580 744000)) nil (25666 39894 907940 976000) 0 nil])
([nil nil ((318 . 325) (#("INFO" 0 4 (fontified t)) . 318) (t 25661 19481 350972 511000)) nil (25666 39894 907939 243000) 0 nil])
([nil nil ((1755 . 1757) (t 25661 29114 877149 490000)) nil (25666 39894 907938 203000) 0 nil])
([nil nil ((3317 . 3327) ("run_trial" . 3317) (t 25661 47011 237860 730000)) nil (25666 39894 907936 769000) 0 nil])
([nil nil ((16 . 4382) (#("import time
import os

from shutil import copyfile

from contextlib import contextmanager

logger = logging.getLogger('soil')
# logging.basicConfig()
# logger.setLevel(logging.INFO)


@contextmanager
def timer(name='task', pre=\"\", function=logger.info, to_object=None):
    start = time.time()
    function('{}Starting {} at {}.'.format(pre, name,
                                           time.strftime(\"%X\", time.gmtime(start))))
    yield start
    end = time.time()
    function('{}Finished {} at {} in {} seconds'.format(pre, name,
                                                        time.strftime(\"%X\", time.gmtime(end)),
                                                        str(end-start)))
    if to_object:
        to_object.start = start
        to_object.end = end




def safe_open(path, mode='r', backup=True, **kwargs):
    outdir = os.path.dirname(path)
    if outdir and not os.path.exists(outdir):
        os.makedirs(outdir)
    if backup and 'w' in mode and os.path.exists(path):
        creation = os.path.getctime(path)
        stamp = time.strftime('%Y-%m-%d_%H.%M.%S', time.localtime(creation))

        backup_dir = os.path.join(outdir, 'backup')
        if not os.path.exists(backup_dir):
            os.makedirs(backup_dir)
        newpath = os.path.join(backup_dir, '{}@{}'.format(os.path.basename(path),
                                                               stamp))
        copyfile(path, newpath)
    return open(path, mode=mode, **kwargs)


def open_or_reuse(f, *args, **kwargs):
    try:
        return safe_open(f, *args, **kwargs)
    except (AttributeError, TypeError):
        return f

def flatten_dict(d):
    if not isinstance(d, dict):
        return d
    return dict(_flatten_dict(d))

def _flatten_dict(d, prefix=''):
    if not isinstance(d, dict):
        # print('END:', prefix, d)
        yield prefix, d
        return
    if prefix:
        prefix = prefix + '.'
    for k, v in d.items():
        # print(k, v)
        res = list(_flatten_dict(v, prefix='{}{}'.format(prefix, k)))
        # print('RES:', res)
        yield from res


def unflatten_dict(d):
    out = {}
    for k, v in d.items():
        target = out
        if not isinstance(k, str):
            target[k] = v
            continue
        tokens = k.split('.')
        if len(tokens) < 2:
            target[k] = v
            continue
        for token in tokens[:-1]:
            if token not in target:
                target[token] = {}
            target = target[token]
        target[tokens[-1]] = v
    return out
" 0 2558 (fontified nil)) . 16) (t 25666 29691 517226 411000) (16 . 2574) (#("from time import time as current_time, strftime, gmtime, localtime
import os
import traceback

from functools import partial
from shutil import copyfile, move
from multiprocessing import Pool, cpu_count

from contextlib import contextmanager

logger = logging.getLogger(\"soil\")
logger.setLevel(logging.WARNING)

timeformat = \"%H:%M:%S\"

if os.environ.get(\"SOIL_VERBOSE\", \"\"):
    logformat = \"[%(levelname)-5.5s][%(asctime)s][%(name)s]:  %(message)s\"
else:
    logformat = \"[%(levelname)-5.5s][%(asctime)s] %(message)s\"

logFormatter = logging.Formatter(logformat, timeformat)
consoleHandler = logging.StreamHandler()
consoleHandler.setFormatter(logFormatter)

logging.basicConfig(
    level=logging.INFO,
    handlers=[
        consoleHandler,
    ],
)


@contextmanager
def timer(name=\"task\", pre=\"\", function=logger.info, to_object=None):
    start = current_time()
    function(\"{}Starting {} at {}.\".format(pre, name, strftime(\"%X\", gmtime(start))))
    yield start
    end = current_time()
    function(
        \"{}Finished {} at {} in {} seconds\".format(
            pre, name, strftime(\"%X\", gmtime(end)), str(end - start)
        )
    )
    if to_object:
        to_object.start = start
        to_object.end = end


def try_backup(path, remove=False):
    if not os.path.exists(path):
        return None
    outdir = os.path.dirname(path)
    if outdir and not os.path.exists(outdir):
        os.makedirs(outdir)
    creation = os.path.getctime(path)
    stamp = strftime(\"%Y-%m-%d_%H.%M.%S\", localtime(creation))

    backup_dir = os.path.join(outdir, \"backup\")
    if not os.path.exists(backup_dir):
        os.makedirs(backup_dir)
    newpath = os.path.join(backup_dir, \"{}@{}\".format(os.path.basename(path), stamp))
    if remove:
        move(path, newpath)
    else:
        copyfile(path, newpath)
    return newpath


def safe_open(path, mode=\"r\", backup=True, **kwargs):
    outdir = os.path.dirname(path)
    if outdir and not os.path.exists(outdir):
        os.makedirs(outdir)
    if backup and \"w\" in mode:
        try_backup(path)
    return open(path, mode=mode, **kwargs)


@contextmanager
def open_or_reuse(f, *args, **kwargs):
    try:
        with safe_open(f, *args, **kwargs) as f:
            yield f
    except (AttributeError, TypeError) as ex:
        yield f


def flatten_dict(d):
    if not isinstance(d, dict):
        return d
    return dict(_flatten_dict(d))


def _flatten_dict(d, prefix=\"\"):
    if not isinstance(d, dict):
        # print('END:', prefix, d)
        yield prefix, d
        return
    if prefix:
        prefix = prefix + \".\"
    for k, v in d.items():
        # print(k, v)
        res = list(_flatten_dict(v, prefix=\"{}{}\".format(prefix, k)))
        # print('RES:', res)
        yield from res


def unflatten_dict(d):
    out = {}
    for k, v in d.items():
        target = out
        if not isinstance(k, str):
            target[k] = v
            continue
        tokens = k.split(\".\")
        if len(tokens) < 2:
            target[k] = v
            continue
        for token in tokens[:-1]:
            if token not in target:
                target[token] = {}
            target = target[token]
        target[tokens[-1]] = v
    return out


def run_and_return_exceptions(func, *args, **kwargs):
    \"\"\"
    A wrapper for a function that catches exceptions and returns them.
    It is meant for async simulations.
    \"\"\"
    try:
        return func(*args, **kwargs)
    except Exception as ex:
        if ex.__cause__ is not None:
            ex = ex.__cause__
        ex.message = \"\".join(
            traceback.format_exception(type(ex), ex, ex.__traceback__)[:]
        )
        return ex


def run_parallel(func, iterable, num_processes=1, **kwargs):
    if num_processes > 1 and not os.environ.get(\"SOIL_DEBUG\", None):
        if num_processes < 1:
            num_processes = cpu_count() - num_processes
        p = Pool(processes=num_processes)
        wrapped_func = partial(run_and_return_exceptions, func, **kwargs)
        for i in p.imap_unordered(wrapped_func, iterable):
            if isinstance(i, Exception):
                logger.error(\"Trial failed:\\n\\t%s\", i.message)
                continue
            yield i
    else:
        for i in iterable:
            yield func(i, **kwargs)


def int_seed(seed: str):
    return int.from_bytes(seed.encode(), \"little\")" 0 4 (fontified t face font-lock-keyword-face) 4 10 (fontified t) 10 16 (fontified t face font-lock-keyword-face) 16 22 (fontified t) 22 24 (fontified t face font-lock-keyword-face) 24 67 (fontified t) 67 73 (fontified t face font-lock-keyword-face) 73 77 (fontified t) 77 83 (fontified t face font-lock-keyword-face) 83 95 (fontified t) 95 99 (fontified t face font-lock-keyword-face) 99 110 (fontified t) 110 116 (fontified t face font-lock-keyword-face) 116 125 (fontified t) 125 129 (fontified t face font-lock-keyword-face) 129 137 (fontified t) 137 143 (fontified t face font-lock-keyword-face) 143 159 (fontified t) 159 163 (fontified t face font-lock-keyword-face) 163 180 (fontified t) 180 186 (fontified t face font-lock-keyword-face) 186 204 (fontified t) 204 208 (fontified t face font-lock-keyword-face) 208 220 (fontified t) 220 226 (fontified t face font-lock-keyword-face) 226 243 (fontified t) 243 249 (fontified t face font-lock-variable-name-face) 249 269 (fontified t) 269 270 (fontified t face (rainbow-delimiters-depth-1-face)) 270 271 (fontified t syntax-table (15) face font-lock-string-face) 271 275 (fontified t face font-lock-string-face) 275 276 (fontified t syntax-table (15) face font-lock-string-face) 276 277 (fontified t face (rainbow-delimiters-depth-1-face)) 277 278 (fontified t) 293 294 (face (rainbow-delimiters-depth-1-face)) 309 310 (face (rainbow-delimiters-depth-1-face)) 312 322 (face font-lock-variable-name-face) 325 326 (syntax-table (15) face font-lock-string-face) 326 334 (face font-lock-string-face) 334 335 (syntax-table (15) face font-lock-string-face) 337 339 (face font-lock-keyword-face) 354 355 (face (rainbow-delimiters-depth-1-face)) 355 356 (syntax-table (15) face font-lock-string-face) 356 368 (face font-lock-string-face) 368 369 (syntax-table (15) face font-lock-string-face) 371 372 (syntax-table (15) face font-lock-string-face) 372 373 (syntax-table (15) face font-lock-string-face) 373 374 (face (rainbow-delimiters-depth-1-face)) 380 389 (face font-lock-variable-name-face) 392 393 (syntax-table (15) face font-lock-string-face) 393 449 (face font-lock-string-face) 449 450 (syntax-table (15) face font-lock-string-face) 451 455 (face font-lock-keyword-face) 461 470 (face font-lock-variable-name-face) 473 474 (syntax-table (15) face font-lock-string-face) 474 488 (face font-lock-string-face) 488 518 (face font-lock-string-face) 518 519 (syntax-table (15) face font-lock-string-face) 521 533 (face font-lock-variable-name-face) 553 554 (face (rainbow-delimiters-depth-1-face)) 575 576 (face (rainbow-delimiters-depth-1-face)) 577 591 (face font-lock-variable-name-face) 615 616 (face (rainbow-delimiters-depth-1-face)) 616 617 (face (rainbow-delimiters-depth-1-face)) 645 646 (face (rainbow-delimiters-depth-1-face)) 658 659 (face (rainbow-delimiters-depth-1-face)) 680 681 (face (rainbow-delimiters-depth-1-face)) 719 720 (face (rainbow-delimiters-depth-2-face)) 749 750 (face (rainbow-delimiters-depth-2-face)) 752 753 (face (rainbow-delimiters-depth-1-face)) 756 771 (face font-lock-type-face) 772 775 (face font-lock-keyword-face) 776 781 (face font-lock-function-name-face) 781 782 (face (rainbow-delimiters-depth-1-face)) 787 788 (syntax-table (15) face font-lock-string-face) 788 792 (face font-lock-string-face) 792 793 (syntax-table (15) face font-lock-string-face) 799 800 (syntax-table (15) face font-lock-string-face) 800 801 (syntax-table (15) face font-lock-string-face) 835 839 (face font-lock-constant-face) 839 840 (face (rainbow-delimiters-depth-1-face)) 846 851 (face font-lock-variable-name-face) 866 867 (face (rainbow-delimiters-depth-1-face)) 867 868 (face (rainbow-delimiters-depth-1-face)) 881 882 (face (rainbow-delimiters-depth-1-face)) 882 883 (syntax-table (15) face font-lock-string-face) 883 903 (face font-lock-string-face) 903 904 (syntax-table (15) face font-lock-string-face) 905 911 (face font-lock-builtin-face) 911 912 (face (rainbow-delimiters-depth-2-face)) 931 932 (face (rainbow-delimiters-depth-3-face)) 932 933 (syntax-table (15) face font-lock-string-face) 933 935 (face font-lock-string-face) 935 936 (syntax-table (15) face font-lock-string-face) 944 945 (face (rainbow-delimiters-depth-4-face)) 950 951 (face (rainbow-delimiters-depth-4-face)) 951 952 (face (rainbow-delimiters-depth-3-face)) 952 953 (face (rainbow-delimiters-depth-2-face)) 953 954 (face (rainbow-delimiters-depth-1-face)) 959 964 (face font-lock-keyword-face) 975 978 (face font-lock-variable-name-face) 993 994 (face (rainbow-delimiters-depth-1-face)) 994 995 (face (rainbow-delimiters-depth-1-face)) 1008 1009 (face (rainbow-delimiters-depth-1-face)) 1018 1019 (syntax-table (15) face font-lock-string-face) 1019 1052 (face font-lock-string-face) 1052 1053 (syntax-table (15) face font-lock-string-face) 1054 1060 (face font-lock-builtin-face) 1060 1061 (face (rainbow-delimiters-depth-2-face)) 1093 1094 (face (rainbow-delimiters-depth-3-face)) 1094 1095 (syntax-table (15) face font-lock-string-face) 1095 1097 (face font-lock-string-face) 1097 1098 (syntax-table (15) face font-lock-string-face) 1106 1107 (face (rainbow-delimiters-depth-4-face)) 1110 1111 (face (rainbow-delimiters-depth-4-face)) 1111 1112 (face (rainbow-delimiters-depth-3-face)) 1114 1117 (face font-lock-builtin-face) 1117 1118 (face (rainbow-delimiters-depth-3-face)) 1129 1130 (face (rainbow-delimiters-depth-3-face)) 1139 1140 (face (rainbow-delimiters-depth-2-face)) 1145 1146 (face (rainbow-delimiters-depth-1-face)) 1151 1153 (face font-lock-keyword-face) 1173 1188 (face font-lock-variable-name-face) 1205 1206 (face font-lock-variable-name-face) 1206 1218 (face font-lock-variable-name-face) 1227 1230 (face font-lock-keyword-face) 1231 1241 (face font-lock-function-name-face) 1241 1242 (face (rainbow-delimiters-depth-1-face)) 1255 1260 (face font-lock-constant-face) 1260 1261 (face (rainbow-delimiters-depth-1-face)) 1267 1269 (face font-lock-keyword-face) 1270 1273 (face font-lock-keyword-face) 1288 1289 (face (rainbow-delimiters-depth-1-face)) 1293 1294 (face (rainbow-delimiters-depth-1-face)) 1304 1310 (face font-lock-keyword-face) 1311 1315 (face font-lock-constant-face) 1320 1326 (face font-lock-variable-name-face) 1344 1345 (face (rainbow-delimiters-depth-1-face)) 1349 1350 (face (rainbow-delimiters-depth-1-face)) 1355 1357 (face font-lock-keyword-face) 1365 1368 (face font-lock-keyword-face) 1369 1372 (face font-lock-keyword-face) 1387 1388 (face (rainbow-delimiters-depth-1-face)) 1394 1395 (face (rainbow-delimiters-depth-1-face)) 1416 1417 (face (rainbow-delimiters-depth-1-face)) 1423 1424 (face (rainbow-delimiters-depth-1-face)) 1429 1437 (face font-lock-variable-name-face) 1456 1457 (face (rainbow-delimiters-depth-1-face)) 1461 1462 (face (rainbow-delimiters-depth-1-face)) 1467 1472 (face font-lock-variable-name-face) 1483 1484 (face (rainbow-delimiters-depth-1-face)) 1484 1485 (face font-lock-string-face syntax-table (15)) 1485 1487 (face font-lock-string-face) 1487 1502 (face font-lock-string-face) 1502 1503 (face font-lock-string-face syntax-table (15)) 1514 1515 (face (rainbow-delimiters-depth-2-face)) 1523 1524 (face (rainbow-delimiters-depth-2-face)) 1524 1525 (face (rainbow-delimiters-depth-1-face)) 1531 1541 (face font-lock-variable-name-face) 1556 1557 (face (rainbow-delimiters-depth-1-face)) 1565 1566 (face font-lock-string-face syntax-table (15)) 1566 1572 (face font-lock-string-face) 1572 1573 (face font-lock-string-face syntax-table (15)) 1573 1574 (face (rainbow-delimiters-depth-1-face)) 1579 1581 (face font-lock-keyword-face) 1582 1585 (face font-lock-keyword-face) 1600 1601 (face (rainbow-delimiters-depth-1-face)) 1611 1612 (face (rainbow-delimiters-depth-1-face)) 1633 1634 (face (rainbow-delimiters-depth-1-face)) 1644 1645 (face (rainbow-delimiters-depth-1-face)) 1650 1657 (face font-lock-variable-name-face) 1672 1673 (face (rainbow-delimiters-depth-1-face)) 1685 1686 (face font-lock-string-face syntax-table (15)) 1686 1691 (face font-lock-string-face) 1691 1692 (face font-lock-string-face syntax-table (15)) 1693 1699 (face font-lock-builtin-face) 1699 1700 (face (rainbow-delimiters-depth-2-face)) 1716 1717 (face (rainbow-delimiters-depth-3-face)) 1721 1722 (face (rainbow-delimiters-depth-3-face)) 1729 1730 (face (rainbow-delimiters-depth-2-face)) 1730 1731 (face (rainbow-delimiters-depth-1-face)) 1736 1738 (face font-lock-keyword-face) 1759 1760 (face (rainbow-delimiters-depth-1-face)) 1773 1774 (face (rainbow-delimiters-depth-1-face)) 1779 1783 (face font-lock-keyword-face) 1801 1802 (face (rainbow-delimiters-depth-1-face)) 1815 1816 (face (rainbow-delimiters-depth-1-face)) 1821 1827 (face font-lock-keyword-face) 1838 1841 (face font-lock-keyword-face) 1842 1851 (face font-lock-function-name-face) 1851 1852 (face (rainbow-delimiters-depth-1-face)) 1863 1864 (face font-lock-string-face syntax-table (15)) 1864 1865 (face font-lock-string-face) 1865 1866 (face font-lock-string-face syntax-table (15)) 1875 1879 (face font-lock-constant-face) 1889 1890 (face (rainbow-delimiters-depth-1-face)) 1896 1902 (face font-lock-variable-name-face) 1920 1921 (face (rainbow-delimiters-depth-1-face)) 1925 1926 (face (rainbow-delimiters-depth-1-face)) 1931 1933 (face font-lock-keyword-face) 1941 1944 (face font-lock-keyword-face) 1945 1948 (face font-lock-keyword-face) 1963 1964 (face (rainbow-delimiters-depth-1-face)) 1970 1971 (face (rainbow-delimiters-depth-1-face)) 1992 1993 (face (rainbow-delimiters-depth-1-face)) 1999 2000 (face (rainbow-delimiters-depth-1-face)) 2019 2020 (syntax-table (15)) 2021 2022 (syntax-table (15)) 2433 2434 (syntax-table (15)) 2434 2435 (syntax-table (15)) 2486 2487 (syntax-table (15)) 2491 2492 (syntax-table (15)) 2585 2586 (syntax-table (15)) 2587 2588 (syntax-table (15)) 2681 2682 (syntax-table (15)) 2686 2687 (syntax-table (15)) 2724 2725 (syntax-table (15)) 2729 2730 (syntax-table (15)) 2953 2954 (syntax-table (15)) 2955 2956 (syntax-table (15))) . 16) (undo-tree-id3 . -1241) (undo-tree-id4 . -1241) (undo-tree-id5 . -1241) (undo-tree-id6 . -451) (undo-tree-id7 . -4289) (undo-tree-id8 . -4289) (undo-tree-id9 . 3662) (undo-tree-id10 . -703) (undo-tree-id11 . -703) (undo-tree-id12 . -203) (undo-tree-id13 . -703) (undo-tree-id14 . -703) (undo-tree-id15 . -203) (undo-tree-id16 . -203) (undo-tree-id17 . -703) (t 25661 47661 22731 867000)) nil (25666 39894 907933 990000) 0 nil])
([nil nil ((16 . 2574) (#("from time import time as current_time, strftime, gmtime, localtime
import os
import traceback

from functools import partial
from shutil import copyfile, move
from multiprocessing import Pool, cpu_count

from contextlib import contextmanager

logger = logging.getLogger(\"soil\")
logger.setLevel(logging.WARNING)

timeformat = \"%H:%M:%S\"

if os.environ.get(\"SOIL_VERBOSE\", \"\"):
    logformat = \"[%(levelname)-5.5s][%(asctime)s][%(name)s]:  %(message)s\"
else:
    logformat = \"[%(levelname)-5.5s][%(asctime)s] %(message)s\"

logFormatter = logging.Formatter(logformat, timeformat)
consoleHandler = logging.StreamHandler()
consoleHandler.setFormatter(logFormatter)

logging.basicConfig(
    level=logging.INFO,
    handlers=[
        consoleHandler,
    ],
)


@contextmanager
def timer(name=\"task\", pre=\"\", function=logger.info, to_object=None):
    start = current_time()
    function(\"{}Starting {} at {}.\".format(pre, name, strftime(\"%X\", gmtime(start))))
    yield start
    end = current_time()
    function(
        \"{}Finished {} at {} in {} seconds\".format(
            pre, name, strftime(\"%X\", gmtime(end)), str(end - start)
        )
    )
    if to_object:
        to_object.start = start
        to_object.end = end


def try_backup(path, remove=False):
    if not os.path.exists(path):
        return None
    outdir = os.path.dirname(path)
    if outdir and not os.path.exists(outdir):
        os.makedirs(outdir)
    creation = os.path.getctime(path)
    stamp = strftime(\"%Y-%m-%d_%H.%M.%S\", localtime(creation))

    backup_dir = os.path.join(outdir, \"backup\")
    if not os.path.exists(backup_dir):
        os.makedirs(backup_dir)
    newpath = os.path.join(backup_dir, \"{}@{}\".format(os.path.basename(path), stamp))
    if remove:
        move(path, newpath)
    else:
        copyfile(path, newpath)
    return newpath


def safe_open(path, mode=\"r\", backup=True, **kwargs):
    outdir = os.path.dirname(path)
    if outdir and not os.path.exists(outdir):
        os.makedirs(outdir)
    if backup and \"w\" in mode:
        try_backup(path)
    return open(path, mode=mode, **kwargs)


@contextmanager
def open_or_reuse(f, *args, **kwargs):
    try:
        with safe_open(f, *args, **kwargs) as f:
            yield f
    except (AttributeError, TypeError) as ex:
        yield f


def flatten_dict(d):
    if not isinstance(d, dict):
        return d
    return dict(_flatten_dict(d))


def _flatten_dict(d, prefix=\"\"):
    if not isinstance(d, dict):
        # print('END:', prefix, d)
        yield prefix, d
        return
    if prefix:
        prefix = prefix + \".\"
    for k, v in d.items():
        # print(k, v)
        res = list(_flatten_dict(v, prefix=\"{}{}\".format(prefix, k)))
        # print('RES:', res)
        yield from res


def unflatten_dict(d):
    out = {}
    for k, v in d.items():
        target = out
        if not isinstance(k, str):
            target[k] = v
            continue
        tokens = k.split(\".\")
        if len(tokens) < 2:
            target[k] = v
            continue
        for token in tokens[:-1]:
            if token not in target:
                target[token] = {}
            target = target[token]
        target[tokens[-1]] = v
    return out


def run_and_return_exceptions(func, *args, **kwargs):
    \"\"\"
    A wrapper for a function that catches exceptions and returns them.
    It is meant for async simulations.
    \"\"\"
    try:
        return func(*args, **kwargs)
    except Exception as ex:
        if ex.__cause__ is not None:
            ex = ex.__cause__
        ex.message = \"\".join(
            traceback.format_exception(type(ex), ex, ex.__traceback__)[:]
        )
        return ex


def run_parallel(func, iterable, num_processes=1, **kwargs):
    if num_processes > 1 and not os.environ.get(\"SOIL_DEBUG\", None):
        if num_processes < 1:
            num_processes = cpu_count() - num_processes
        p = Pool(processes=num_processes)
        wrapped_func = partial(run_and_return_exceptions, func, **kwargs)
        for i in p.imap_unordered(wrapped_func, iterable):
            if isinstance(i, Exception):
                logger.error(\"Trial failed:\\n\\t%s\", i.message)
                continue
            yield i
    else:
        for i in iterable:
            yield func(i, **kwargs)


def int_seed(seed: str):
    return int.from_bytes(seed.encode(), \"little\")" 0 4366 (fontified nil)) . 16) (t 25666 29697 925166 749000)) nil (25666 39894 907913 324000) 0 nil])
([nil nil ((16 . 4382) (#("import time
import os

from shutil import copyfile

from contextlib import contextmanager

logger = logging.getLogger('soil')
# logging.basicConfig()
# logger.setLevel(logging.INFO)


@contextmanager
def timer(name='task', pre=\"\", function=logger.info, to_object=None):
    start = time.time()
    function('{}Starting {} at {}.'.format(pre, name,
                                           time.strftime(\"%X\", time.gmtime(start))))
    yield start
    end = time.time()
    function('{}Finished {} at {} in {} seconds'.format(pre, name,
                                                        time.strftime(\"%X\", time.gmtime(end)),
                                                        str(end-start)))
    if to_object:
        to_object.start = start
        to_object.end = end




def safe_open(path, mode='r', backup=True, **kwargs):
    outdir = os.path.dirname(path)
    if outdir and not os.path.exists(outdir):
        os.makedirs(outdir)
    if backup and 'w' in mode and os.path.exists(path):
        creation = os.path.getctime(path)
        stamp = time.strftime('%Y-%m-%d_%H.%M.%S', time.localtime(creation))

        backup_dir = os.path.join(outdir, 'backup')
        if not os.path.exists(backup_dir):
            os.makedirs(backup_dir)
        newpath = os.path.join(backup_dir, '{}@{}'.format(os.path.basename(path),
                                                               stamp))
        copyfile(path, newpath)
    return open(path, mode=mode, **kwargs)


def open_or_reuse(f, *args, **kwargs):
    try:
        return safe_open(f, *args, **kwargs)
    except (AttributeError, TypeError):
        return f

def flatten_dict(d):
    if not isinstance(d, dict):
        return d
    return dict(_flatten_dict(d))

def _flatten_dict(d, prefix=''):
    if not isinstance(d, dict):
        # print('END:', prefix, d)
        yield prefix, d
        return
    if prefix:
        prefix = prefix + '.'
    for k, v in d.items():
        # print(k, v)
        res = list(_flatten_dict(v, prefix='{}{}'.format(prefix, k)))
        # print('RES:', res)
        yield from res


def unflatten_dict(d):
    out = {}
    for k, v in d.items():
        target = out
        if not isinstance(k, str):
            target[k] = v
            continue
        tokens = k.split('.')
        if len(tokens) < 2:
            target[k] = v
            continue
        for token in tokens[:-1]:
            if token not in target:
                target[token] = {}
            target = target[token]
        target[tokens[-1]] = v
    return out
" 0 2558 (fontified nil)) . 16) (t 25666 30169 464892 318000)) nil (25666 39894 907911 627000) 0 nil])
([nil current ((16 . 4382) (#("import time
import os

from shutil import copyfile

from contextlib import contextmanager

logger = logging.getLogger('soil')
# logging.basicConfig()
# logger.setLevel(logging.INFO)


@contextmanager
def timer(name='task', pre=\"\", function=logger.info, to_object=None):
    start = time.time()
    function('{}Starting {} at {}.'.format(pre, name,
                                           time.strftime(\"%X\", time.gmtime(start))))
    yield start
    end = time.time()
    function('{}Finished {} at {} in {} seconds'.format(pre, name,
                                                        time.strftime(\"%X\", time.gmtime(end)),
                                                        str(end-start)))
    if to_object:
        to_object.start = start
        to_object.end = end




def safe_open(path, mode='r', backup=True, **kwargs):
    outdir = os.path.dirname(path)
    if outdir and not os.path.exists(outdir):
        os.makedirs(outdir)
    if backup and 'w' in mode and os.path.exists(path):
        creation = os.path.getctime(path)
        stamp = time.strftime('%Y-%m-%d_%H.%M.%S', time.localtime(creation))

        backup_dir = os.path.join(outdir, 'backup')
        if not os.path.exists(backup_dir):
            os.makedirs(backup_dir)
        newpath = os.path.join(backup_dir, '{}@{}'.format(os.path.basename(path),
                                                               stamp))
        copyfile(path, newpath)
    return open(path, mode=mode, **kwargs)


def open_or_reuse(f, *args, **kwargs):
    try:
        return safe_open(f, *args, **kwargs)
    except (AttributeError, TypeError):
        return f

def flatten_dict(d):
    if not isinstance(d, dict):
        return d
    return dict(_flatten_dict(d))

def _flatten_dict(d, prefix=''):
    if not isinstance(d, dict):
        # print('END:', prefix, d)
        yield prefix, d
        return
    if prefix:
        prefix = prefix + '.'
    for k, v in d.items():
        # print(k, v)
        res = list(_flatten_dict(v, prefix='{}{}'.format(prefix, k)))
        # print('RES:', res)
        yield from res


def unflatten_dict(d):
    out = {}
    for k, v in d.items():
        target = out
        if not isinstance(k, str):
            target[k] = v
            continue
        tokens = k.split('.')
        if len(tokens) < 2:
            target[k] = v
            continue
        for token in tokens[:-1]:
            if token not in target:
                target[token] = {}
            target = target[token]
        target[tokens[-1]] = v
    return out
" 0 2558 (fontified nil)) . 16) (t 25666 33091 270318 327000) (16 . 2574) (#("from time import time as current_time, strftime, gmtime, localtime
import os
import traceback

from functools import partial
from shutil import copyfile, move
from multiprocessing import Pool, cpu_count

from contextlib import contextmanager

logger = logging.getLogger(\"soil\")
logger.setLevel(logging.WARNING)

timeformat = \"%H:%M:%S\"

if os.environ.get(\"SOIL_VERBOSE\", \"\"):
    logformat = \"[%(levelname)-5.5s][%(asctime)s][%(name)s]:  %(message)s\"
else:
    logformat = \"[%(levelname)-5.5s][%(asctime)s] %(message)s\"

logFormatter = logging.Formatter(logformat, timeformat)
consoleHandler = logging.StreamHandler()
consoleHandler.setFormatter(logFormatter)

logging.basicConfig(
    level=logging.INFO,
    handlers=[
        consoleHandler,
    ],
)


@contextmanager
def timer(name=\"task\", pre=\"\", function=logger.info, to_object=None):
    start = current_time()
    function(\"{}Starting {} at {}.\".format(pre, name, strftime(\"%X\", gmtime(start))))
    yield start
    end = current_time()
    function(
        \"{}Finished {} at {} in {} seconds\".format(
            pre, name, strftime(\"%X\", gmtime(end)), str(end - start)
        )
    )
    if to_object:
        to_object.start = start
        to_object.end = end


def try_backup(path, remove=False):
    if not os.path.exists(path):
        return None
    outdir = os.path.dirname(path)
    if outdir and not os.path.exists(outdir):
        os.makedirs(outdir)
    creation = os.path.getctime(path)
    stamp = strftime(\"%Y-%m-%d_%H.%M.%S\", localtime(creation))

    backup_dir = os.path.join(outdir, \"backup\")
    if not os.path.exists(backup_dir):
        os.makedirs(backup_dir)
    newpath = os.path.join(backup_dir, \"{}@{}\".format(os.path.basename(path), stamp))
    if remove:
        move(path, newpath)
    else:
        copyfile(path, newpath)
    return newpath


def safe_open(path, mode=\"r\", backup=True, **kwargs):
    outdir = os.path.dirname(path)
    if outdir and not os.path.exists(outdir):
        os.makedirs(outdir)
    if backup and \"w\" in mode:
        try_backup(path)
    return open(path, mode=mode, **kwargs)


@contextmanager
def open_or_reuse(f, *args, **kwargs):
    try:
        with safe_open(f, *args, **kwargs) as f:
            yield f
    except (AttributeError, TypeError) as ex:
        yield f


def flatten_dict(d):
    if not isinstance(d, dict):
        return d
    return dict(_flatten_dict(d))


def _flatten_dict(d, prefix=\"\"):
    if not isinstance(d, dict):
        # print('END:', prefix, d)
        yield prefix, d
        return
    if prefix:
        prefix = prefix + \".\"
    for k, v in d.items():
        # print(k, v)
        res = list(_flatten_dict(v, prefix=\"{}{}\".format(prefix, k)))
        # print('RES:', res)
        yield from res


def unflatten_dict(d):
    out = {}
    for k, v in d.items():
        target = out
        if not isinstance(k, str):
            target[k] = v
            continue
        tokens = k.split(\".\")
        if len(tokens) < 2:
            target[k] = v
            continue
        for token in tokens[:-1]:
            if token not in target:
                target[token] = {}
            target = target[token]
        target[tokens[-1]] = v
    return out


def run_and_return_exceptions(func, *args, **kwargs):
    \"\"\"
    A wrapper for a function that catches exceptions and returns them.
    It is meant for async simulations.
    \"\"\"
    try:
        return func(*args, **kwargs)
    except Exception as ex:
        if ex.__cause__ is not None:
            ex = ex.__cause__
        ex.message = \"\".join(
            traceback.format_exception(type(ex), ex, ex.__traceback__)[:]
        )
        return ex


def run_parallel(func, iterable, num_processes=1, **kwargs):
    if num_processes > 1 and not os.environ.get(\"SOIL_DEBUG\", None):
        if num_processes < 1:
            num_processes = cpu_count() - num_processes
        p = Pool(processes=num_processes)
        wrapped_func = partial(run_and_return_exceptions, func, **kwargs)
        for i in p.imap_unordered(wrapped_func, iterable):
            if isinstance(i, Exception):
                logger.error(\"Trial failed:\\n\\t%s\", i.message)
                continue
            yield i
    else:
        for i in iterable:
            yield func(i, **kwargs)


def int_seed(seed: str):
    return int.from_bytes(seed.encode(), \"little\")" 0 4366 (fontified nil)) . 16) (t 25666 30273 971966 379000)) nil (25666 39894 907905 134000) 0 nil])
nil
