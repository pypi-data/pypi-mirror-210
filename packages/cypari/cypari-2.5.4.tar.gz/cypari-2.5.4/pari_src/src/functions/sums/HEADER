Function: _header_sums
Class: header
Section: sums
Doc:
 \section{Sums, products, integrals and similar functions}
 \label{se:sums}

 Although the \kbd{gp} calculator is programmable, it is useful to have
 a number of preprogrammed loops, including sums, products, and a certain
 number of recursions. Also, a number of functions from numerical analysis
 like numerical integration and summation of series will be described here.

 One of the parameters in these loops must be the control variable, hence a
 simple variable name. In the descriptions, the letter $X$ will always denote
 any simple variable name, and represents the formal parameter used in the
 function. The expression to be summed, integrated, etc. is any legal PARI
 expression, including of course expressions using loops.

 \misctitle{Library mode}
 Since it is easier to program directly the loops in library mode, these
 functions are mainly useful for GP programming. On the other hand, numerical
 routines code a function (to be integrated, summed, etc.) with two parameters
 named
 \bprog
   GEN (*eval)(void*,GEN)
   void *E;  \\ context: eval(E, x) must evaluate your function at x.
 @eprog\noindent
 see the Libpari manual for details.

 \misctitle{Numerical integration}\sidx{numerical integration}
 The ``double exponential'' (DE) univariate
 integration method is implemented in \tet{intnum} and its variants. Romberg
 integration is still available under the name \tet{intnumromb}, but
 superseded. It is possible to compute numerically integrals to thousands of
 decimal places in reasonable time, as long as the integrand is regular. It is
 also reasonable to compute numerically integrals in several variables,
 although more than two becomes lengthy. The integration domain may be
 noncompact, and the integrand may have reasonable singularities at
 endpoints. To use \kbd{intnum}, you must split the integral into a sum
 of subintegrals where the function has no singularities except at the
 endpoints. Polynomials in logarithms are not considered singular, and
 neglecting these logs, singularities are assumed to be algebraic (asymptotic
 to $C(x-a)^{-\alpha}$ for some $\alpha > -1$ when $x$ is
 close to $a$), or to correspond to simple discontinuities of some (higher)
 derivative of the function. For instance, the point $0$ is a singularity of
 $\text{abs}(x)$.

 Assume the bitprecision is $b$, so we try to achieve an absolute error less
 than $2^{-b}$. DE methods use $O(b \log b)$ function evaluations and should
 work for both compact and non-compact intervals as long as the integrand is
 the restriction of an analytic function to a suitable domain and its behaviour
 at infinity is correctly described.
 When integrating regular functions on a \emph{compact} interval, away from
 poles of the integrand, Gauss-Legendre integration (\tet{intnumgauss})
 is the best choice, using $O(b)$ function evaluations. To integrate
 oscillating functions on non-compact interval, the slower but robust
 \tet{intnumosc} is available, performing Gaussian integration on intervals of
 length the half-period (or quasi-period) and using Sidi's $mW$ algorithm to
 extrapolate their sum. If poles are close to the integration interval,
 Gaussian integration may run into difficulties and it is then advisable to
 split the integral using \kbd{intnum} to get away from poles, then
 \kbd{intnumosc} for the remainder.

 For maximal efficiency, abscissas and integration
 weights can be precomputed, respectively using \tet{intnuminit} ($O(b^2)$)
 or \tet{intnumgaussinit} ($O(b^3)$).

 \misctitle{Numerical summation}\sidx{numerical summation}

 Many numerical summation methods are available to approximate
 $\sum_{n\geq n_0} f(n)$ at accuracy $2^{-b}$: the overall best choice should
 be \tet{sumnum}, which uses Euler-MacLaurin (and $O(b\log b)$ function
 evaluations); initialization time (\tet{sumnuminit}) is $O(b^3)$.
 Also available are

 \item Abel-Plana summation (\tet{sumnumap}),
 also $O(b\log b)$ function evaluations and $O(b^3)$ initialization
 (\tet{sumnumapinit}) with a larger implied constant;

 \item Lagrange summation (\tet{sumnumlagrange}) uses $O(b)$ evaluations
 but more brittle and the asymptotic behaviour of $f$ must be correctly
 indicated. Initialization (\tet{sumnumlagrangeinit}) can vary from $O(b^2)$
 to $O(b^3)$ depending on the asymptotic behaviour.

 \item Sidi summation (\tet{sumnumsidi}) uses $O(b)$ evaluations and should
 be more robust than Lagrange summation. No initialization is needed.

 \item Monien summation (\tet{sumnummonien}) uses $O(b/\log b)$ evaluations
 but is even more brittle than Lagrange and also has a $O(b^3)$ initialization
 (\kbd{summonieninit}).

 \item To sum rational functions, use \tet{sumnumrat}.

 All the function so far require $f$ to be be the restriction to integers
 of a regular function on the reals, and even on the complex numbers for
 Monien summation. The following algorithms allow functions defined
 only on the integers, under asumptions that are hard to verify. They are
 best used heuristically since they in fact are often valid when those
 asumptions do not hold, and for instance often yield a result for divergent
 series (e.g., Borel resummation).

 \item To sum alternating series, use \tet{sumalt}, which requires
 $O(b)$ function evaluations.

 \item To sum functions of a fixed sign, \tet{sumpos}
 uses van Wijngarten's trick to reduce to an alternating series,
 for a cost of $O(b\log b)$ function evaluations but beware that $f$ must be
 evaluated at large integers, of the order of $2^{b/\alpha}$ if we assume
 that $f(n) = O(1 / n^{\alpha+1})$ for some $\alpha > 0$.
