{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkABbuTvbkfJ"
      },
      "source": [
        "**LP5- High Performance Computing Practical 4**\n",
        "\n",
        "Write a CUDA Program for :\n",
        "1. Addition of two large vectors\n",
        "2. Matrix Multiplication using CUDA C\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOh6QlPIgYHs",
        "outputId": "5afeb44b-16dd-4764-d548-f681dd7f7c8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q6d20rC4a54e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7a27410b-1058-48ec-a42f-d195d98c8d52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nRemoving all  the previous version\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "\"\"\"\n",
        "Removing all  the previous version\n",
        "\"\"\"\n",
        "# !apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "# !dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "# !apt-get remove cuda-*\n",
        "# !apt autoremove\n",
        "# !apt-get update\n",
        "\n",
        "# !wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin\n",
        "# !sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
        "# !wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda-repo-ubuntu2204-11-8-local_11.8.0-520.61.05-1_amd64.deb\n",
        "# !sudo dpkg -i cuda-repo-ubuntu2204-11-8-local_11.8.0-520.61.05-1_amd64.deb\n",
        "# !sudo cp /var/cuda-repo-ubuntu2204-11-8-local/cuda-*-keyring.gpg /usr/share/keyrings/\n",
        "# !sudo apt-get update\n",
        "# !sudo apt-get -y install cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KXDzzmIcN38"
      },
      "source": [
        "**Installing Libraries** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqs7rmvScNJZ",
        "outputId": "78c15829-2989-4f36-a1cd-45fe5421894e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-p2094r0_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-p2094r0_\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4287 sha256=685ad521addd680e9a8c48cbb01b3460aa01e3652459aea4f11938d469d23d40\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-om5dmfxr/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg3cFwZ-gVIW",
        "outputId": "8a586ed5-6993-4bb5-e042-a480aa6723d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQDrxXfbcJSR"
      },
      "source": [
        "# **Vector Addition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSMeqYa2hxmk",
        "outputId": "3cdf5030-12ad-4f79-e791-5eae60b90588"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector addition on GPU \n",
            "The sum of 0 element is 0 + 0 = 0\n",
            "The sum of 1 element is 2 + 1 = 3\n",
            "The sum of 2 element is 8 + 2 = 10\n",
            "The sum of 3 element is 18 + 3 = 21\n",
            "The sum of 4 element is 32 + 4 = 36\n",
            "The sum of 5 element is 50 + 5 = 55\n",
            "The sum of 6 element is 72 + 6 = 78\n",
            "The sum of 7 element is 98 + 7 = 105\n",
            "The sum of 8 element is 128 + 8 = 136\n",
            "The sum of 9 element is 162 + 9 = 171\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cu\n",
        "#include \"stdio.h\"\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Defining number of elements in Array\n",
        "#define N 10\n",
        "\n",
        "// Defining Kernel function for vector addition\n",
        "__global__ void gpuAdd(int *d_a, int *d_b, int *d_c)\n",
        "{\n",
        "    // Getting block index of current kernel\n",
        "    int tid = blockIdx.x; // handle the data at this index\n",
        "    if (tid < N)\n",
        "        d_c[tid] = d_a[tid] + d_b[tid];\n",
        "}\n",
        "// Main program\n",
        "int main(void)\n",
        "{\n",
        "    // Defining host arrays\n",
        "    int h_a[N], h_b[N], h_c[N];\n",
        "    // Defining device pointers\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    // allocate the memory\n",
        "    cudaMalloc((void**)&d_a, N * sizeof(int));\n",
        "    cudaMalloc((void**)&d_b, N * sizeof(int));\n",
        "    cudaMalloc((void**)&d_c, N * sizeof(int));\n",
        "    // Initializing Arrays\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_a[i] = 2*i*i;\n",
        "        h_b[i] = i ;\n",
        "    }\n",
        "\n",
        "    // Copy input arrays from host to device memory\n",
        "    cudaMemcpy(d_a, h_a, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Calling kernels with N blocks and one thread per block, passing\n",
        "    // device pointers as parameters <<<...>>>execution configuration syntax\n",
        "    gpuAdd <<<N, 1 >>>(d_a, d_b, d_c);\n",
        " \n",
        "    // Copy result back to host memory from device memory\n",
        "    cudaMemcpy(h_c, d_c, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    printf(\"Vector addition on GPU \\n\");\n",
        " \n",
        "    // Printing result on console\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        printf(\"The sum of %d element is %d + %d = %d\\n\",\n",
        "            i, h_a[i], h_b[i],h_c[i]);\n",
        "    }\n",
        "    // Free up memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "454QamR6cpzz"
      },
      "source": [
        "# **Matrix Multiplication** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TieMB_B8cyR4",
        "outputId": "3337b4ce-9a5f-45a9-daa0-a9ad0b244b81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executing Matrix Multiplcation\n",
            "Matrix size: 4x4\n",
            "\n",
            "Input Matrix 1 \n",
            "2\t2\t2\t2\t\n",
            "2\t2\t2\t2\t\n",
            "2\t2\t2\t2\t\n",
            "2\t2\t2\t2\t\n",
            "\n",
            "Input Matrix 2 \n",
            "5\t5\t5\t5\t\n",
            "5\t5\t5\t5\t\n",
            "5\t5\t5\t5\t\n",
            "5\t5\t5\t5\t\n",
            "\n",
            "\n",
            " Resultant matrix\n",
            "\n",
            "40\t40\t40\t40\t\n",
            "40\t40\t40\t40\t\n",
            "40\t40\t40\t40\t\n",
            "40\t40\t40\t40\t\n",
            "Finished.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "#define BLOCK_SIZE 2\n",
        "\n",
        "__global__ void gpuMM(float *A, float *B, float *C, int N)\n",
        "{\n",
        "    // Matrix multiplication for NxN matrices C=A*B\n",
        "    // Each thread computes a single element of C\n",
        "    int row = blockIdx.y*blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "\n",
        "    float sum = 0.f;\n",
        "    for (int i = 0; i < N; ++i)\n",
        "        sum += A[row*N+i]*B[i*N+col];\n",
        "\n",
        "    C[row*N+col] = sum;\n",
        " \n",
        " /*\n",
        " sum += a[row * width + k] * b[k * width + col];\n",
        " c[row * width + col] = sum;\n",
        " k= column\n",
        " */\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[])\n",
        "{\n",
        "    int N;float K;\n",
        "    // Perform matrix multiplication C = A*B\n",
        "    // where A, B and C are NxN matrices\n",
        "    // Restricted to matrices where N = K*BLOCK_SIZE;\n",
        "\t  //cout<<\"Enter a Value for Size/2 of matrix\";\n",
        "\t  //cin>>K;\n",
        "\n",
        "    K = 2;\n",
        "    N = K*BLOCK_SIZE;\n",
        "\n",
        "    cout << \"Executing Matrix Multiplcation\" << endl;\n",
        "    cout << \"Matrix size: \" << N << \"x\" << N << endl;\n",
        "\n",
        "    // Allocate memory on the host\n",
        "    float *hA,*hB,*hC;\n",
        "    hA = new float[N*N];\n",
        "    hB = new float[N*N];\n",
        "    hC = new float[N*N];\n",
        "\n",
        "    // Initialize matrices on the host\n",
        "    for (int j=0; j<N; j++){\n",
        "        for (int i=0; i<N; i++){\n",
        "           hA[j*N+i] = 2;\n",
        "           hB[j*N+i] = 5;\n",
        "\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Allocate memory on the device\n",
        "    int size = N*N*sizeof(float);    // Size of the memory in bytes\n",
        "    float *dA,*dB,*dC;\n",
        "    cudaMalloc(&dA,size);\n",
        "    cudaMalloc(&dB,size);\n",
        "    cudaMalloc(&dC,size);\n",
        "\n",
        "    dim3 threadBlock(BLOCK_SIZE,BLOCK_SIZE);\n",
        "    dim3 grid(K,K);\n",
        " \n",
        "    cout<<\"\\nInput Matrix 1 \\n\";\n",
        "    for (int row=0; row<N; row++){\n",
        "            for (int col=0; col<N; col++){\n",
        "\n",
        "                   cout<<hA[row*col]<<\"\t\";\n",
        "\n",
        "            }\n",
        "            cout<<endl;\n",
        "        }\n",
        " \n",
        "    cout<<\"\\nInput Matrix 2 \\n\";\n",
        "    for (int row=0; row<N; row++){\n",
        "            for (int col=0; col<N; col++){\n",
        "\n",
        "                   cout<<hB[row*col]<<\"\t\";\n",
        "\n",
        "            }\n",
        "            cout<<endl;\n",
        "        }\n",
        " \n",
        "    // Copy matrices from the host to device\n",
        "    cudaMemcpy(dA,hA,size,cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dB,hB,size,cudaMemcpyHostToDevice);\n",
        "\n",
        "    //Execute the matrix multiplication kernel\n",
        "    gpuMM<<<grid,threadBlock>>>(dA,dB,dC,N);\n",
        "\n",
        "          // Now do the matrix multiplication on the CPU\n",
        "          /*float sum;\n",
        "          for (int row=0; row<N; row++){\n",
        "            for (int col=0; col<N; col++){\n",
        "                sum = 0.f;\n",
        "                for (int n=0; n<N; n++){\n",
        "                    sum += hA[row*N+n]*hB[n*N+col];\n",
        "                }\n",
        "                hC[row*N+col] = sum;\n",
        "                cout << sum <<\"\t\";\n",
        "\n",
        "\n",
        "            }\n",
        "            cout<<endl;\n",
        "          }*/\n",
        "\n",
        "   \n",
        "    // Now copy the GPU result back to CPU\n",
        "    cudaMemcpy(hC,dC,size,cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Check the result and make sure it is correct\n",
        "    cout <<\"\\n\\n Resultant matrix\\n\\n\";\n",
        "    for (int row=0; row<N; row++){\n",
        "        for (int col=0; col<N; col++){\n",
        "\n",
        "               cout<<hC[row*col]<<\"\t\";\n",
        "\n",
        "        }\n",
        "        cout<<endl;\n",
        "    }\n",
        "\n",
        "    cout << \"Finished.\" << endl;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "94k7kdf-GJ4j"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}